{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhyRt6ZvZLLXanHS3Hfdbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pengyu-gis/Remote-Sensing-ChatGPT/blob/main/RS_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install timm\n",
        "!pip install -U openmim\n",
        "!pip install gdown\n",
        "!mim install mmcv\n",
        "!pip install openai\n",
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "gal4_qWkIxhN",
        "outputId": "5f9681c2-58e4-4d04-a42e-58f4a4fe8dcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: addict, yapf, mmengine, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-2.1.0 mmengine-0.10.3 yapf-0.40.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33omnD1VIK-b",
        "outputId": "c3223899-26a8-4cc0-f72c-7a393353362b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Remote-Sensing-ChatGPT'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 219 (delta 48), reused 91 (delta 33), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (219/219), 20.38 MiB | 26.15 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HaonanGuo/Remote-Sensing-ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1f-WES6fTGGa5W9BcDPMVhGk3Foc4p9Or'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWtXBB5lIgyr",
        "outputId": "9d8ad14f-7eec-4619-fbbb-4b4533858619"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1f-WES6fTGGa5W9BcDPMVhGk3Foc4p9Or\n",
            "From (redirected): https://drive.google.com/uc?id=1f-WES6fTGGa5W9BcDPMVhGk3Foc4p9Or&confirm=t&uuid=fc273c00-909e-4575-94cc-67c0b8cc410c\n",
            "To: /content/Res34_AID_best.pth\n",
            "100% 85.3M/85.3M [00:00<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1Hb7XA6gZxNam8y8nxs2p6EqJ-XaG1o5Y -O /content/Remote-Sensing-ChatGPT/checkpoints/\n",
        "!gdown --id 165jeD0oi6fSpvWrpgfVBbzUOsyHN0xEq -O /content/Remote-Sensing-ChatGPT/checkpoints/\n",
        "!gdown --id 1fRyEpb7344S4Y5F2Q4EBO3fXVT4kXaft -O /content/Remote-Sensing-ChatGPT/checkpoints/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubn71rQcOwEu",
        "outputId": "c7fae5db-e55a-49c2-ee88-d47a9546d171"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Hb7XA6gZxNam8y8nxs2p6EqJ-XaG1o5Y\n",
            "From (redirected): https://drive.google.com/uc?id=1Hb7XA6gZxNam8y8nxs2p6EqJ-XaG1o5Y&confirm=t&uuid=add9bdcf-c54e-4a05-b546-a4b940fbf66d\n",
            "To: /content/Remote-Sensing-ChatGPT/checkpoints/yolov5_best.pt\n",
            "100% 93.0M/93.0M [00:01<00:00, 64.3MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=165jeD0oi6fSpvWrpgfVBbzUOsyHN0xEq\n",
            "From (redirected): https://drive.google.com/uc?id=165jeD0oi6fSpvWrpgfVBbzUOsyHN0xEq&confirm=t&uuid=18ad1162-b989-46b5-8711-cf86f5107672\n",
            "To: /content/Remote-Sensing-ChatGPT/checkpoints/last_swint_upernet_finetune.pth\n",
            "100% 400M/400M [00:04<00:00, 88.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fRyEpb7344S4Y5F2Q4EBO3fXVT4kXaft\n",
            "From (redirected): https://drive.google.com/uc?id=1fRyEpb7344S4Y5F2Q4EBO3fXVT4kXaft&confirm=t&uuid=f54a14e7-1c53-4965-945c-d782716199f9\n",
            "To: /content/Remote-Sensing-ChatGPT/checkpoints/HRNET_LoveDA_best.pth\n",
            "100% 264M/264M [00:03<00:00, 81.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/chendelong/RemoteCLIP/blob/main/RemoteCLIP-ViT-B-32.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIeiSsLYPVTl",
        "outputId": "abb65475-e137-4da2-abc8-bce4a2428b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-02 19:14:38--  https://huggingface.co/chendelong/RemoteCLIP/blob/main/RemoteCLIP-ViT-B-32.pt\n",
            "Resolving huggingface.co (huggingface.co)... 18.155.173.126, 18.155.173.122, 18.155.173.64, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.155.173.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40756 (40K) [text/html]\n",
            "Saving to: ‘RemoteCLIP-ViT-B-32.pt’\n",
            "\n",
            "\rRemoteCLIP-ViT-B-32   0%[                    ]       0  --.-KB/s               \rRemoteCLIP-ViT-B-32 100%[===================>]  39.80K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-02-02 19:14:38 (17.5 MB/s) - ‘RemoteCLIP-ViT-B-32.pt’ saved [40756/40756]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Remote-Sensing-ChatGPT/RSChatGPT-shell.py --openai_key <your-key> --image_dir /content/20240109194713.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPaya2KZIqu9",
        "outputId": "c818efa9-401b-457b-97cb-7eadb8d4dd7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py:31: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "Initializing RSChatGPT, load_dict={'ImageCaptioning': 'cuda:0', 'SceneClassification': 'cuda:0', 'ObjectDetection': 'cuda:0', 'LandUseSegmentation': 'cuda:0', 'InstanceSegmentation': 'cuda:0', 'ObjectCounting': 'cuda:0', 'EdgeDetection': 'cpu'}\n",
            "Initializing ImageCaptioning to cuda:0\n",
            "2024-02-03 09:36:42.906715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-03 09:36:42.906776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-03 09:36:42.908546: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-03 09:36:44.029871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing SceneClassification\n",
            "Initializing SceneClassification\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Initializing LandUseSegmentation\n",
            "Initializing InstanceSegmentation\n",
            "Initializing InstanceSegmentation\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Initializing Edge Detection Function....\n",
            "Initializing Image2Canny\n",
            "All the Available Functions: {'ImageCaptioning': <__main__.ImageCaptioning object at 0x79e2d42c1cc0>, 'SceneClassification': <__main__.SceneClassification object at 0x79e2d42c1ba0>, 'ObjectDetection': <__main__.ObjectDetection object at 0x79e286555ff0>, 'LandUseSegmentation': <__main__.LandUseSegmentation object at 0x79e286555ea0>, 'InstanceSegmentation': <__main__.InstanceSegmentation object at 0x79e3a493d360>, 'ObjectCounting': <__main__.ObjectCounting object at 0x79e2842b8100>, 'EdgeDetection': <__main__.EdgeDetection object at 0x79e284270070>}\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n",
            "RSChatGPT initialization done, you can now chat with RSChatGPT~\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "\n",
            "Processed ImageCaptioning, Input Image: image/ae31deb1.png, Output Text: A satellite image of a large body of water\n",
            "\n",
            "Processed ImageCaptioning, Input Image: image/ae31deb1.png, Output Text: A satellite image of a large body of water\n",
            "\n",
            "Processed run_image, Input image: image/ae31deb1.png\n",
            "Current state: [('![](file=image/ae31deb1.png)*image/ae31deb1.png*', 'Received.')]\n",
            "Current Memory: Human:  Provide a remote sensing image named image/ae31deb1.png. The description is: A satellite image of a large body of water. This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\".\n",
            "AI: Received.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Count object\n",
            "Action Input: image/ae31deb1.png, plane\u001b[0m\n",
            "Processed Object Counting, Input Image: image/ae31deb1.png, Output text:  plane is not a supported category for the model.\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m plane is not a supported category for the model.\u001b[0m\n",
            "Thought:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Get Photo Description\n",
            "Action Input: image/ae31deb1.png\u001b[0m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "\n",
            "Processed ImageCaptioning, Input Image: image/ae31deb1.png, Output Text: A satellite image of a large body of water\n",
            "\n",
            "Processed ImageCaptioning, Input Image: image/ae31deb1.png, Output Text: A satellite image of a large body of water\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mA satellite image of a large body of water\u001b[0m\n",
            "Thought:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Detect the given object\n",
            "Action Input: image/ae31deb1.png, plane\u001b[0mTraceback (most recent call last):\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RSChatGPT-shell.py\", line 239, in <module>\n",
            "    state=bot.run_image(args.image_dir, [], txt)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RSChatGPT-shell.py\", line 218, in run_image\n",
            "    state=self.run_text(f'{txt} {image_filename} ', state)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RSChatGPT-shell.py\", line 184, in run_text\n",
            "    res = self.agent({\"input\": text.strip()})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 363, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 162, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 156, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\", line 1391, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\", line 1097, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\", line 1097, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\", line 1182, in _iter_next_step\n",
            "    yield self._perform_agent_action(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\", line 1204, in _perform_agent_action\n",
            "    observation = tool.run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\", line 373, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\", line 345, in run\n",
            "    self._run(*tool_args, run_manager=run_manager, **tool_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/tools.py\", line 523, in _run\n",
            "    else self.func(*args, **kwargs)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RSChatGPT-shell.py\", line 124, in inference\n",
            "    log_text=self.func.inference(image_path, det_prompt,updated_image_path)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RStask/ObjectDetection/YOLOv5.py\", line 25, in inference\n",
            "    out, _ = self.model(image.to(self.device), augment=False,val=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RStask/ObjectDetection/models/common.py\", line 307, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize)[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RStask/ObjectDetection/models/yolo.py\", line 135, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RStask/ObjectDetection/models/yolo.py\", line 158, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Remote-Sensing-ChatGPT/RStask/ObjectDetection/models/common.py\", line 276, in forward\n",
            "    return torch.cat(x, self.d)\n",
            "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 78 but got size 77 for tensor number 1 in the list.\n"
          ]
        }
      ]
    }
  ]
}